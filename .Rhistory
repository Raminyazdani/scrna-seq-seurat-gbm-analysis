f1 <- FeatureScatter(gbm,
feature1 = "nCount_RNA",
feature2 = "nFeature_RNA",
group.by = "patient.name")
f2 <- FeatureScatter(gbm,
feature1 = "nCount_RNA",
feature2 = "percent.mt",
group.by = "patient.name")
f3 <- FeatureScatter(gbm,
feature1 = "percent.mt",
feature2 = "nFeature_RNA",
group.by = "patient.name")
plot_dict$FeaturScatterPlots <- wrap_plots(f1, f2, f3)
wrap_plots(f1, f2, f3)
rm(f1, f2, f3)
# Function to calculate summary statistics
calculate_stats <- function(x) {
return(
c(
min = min(x, na.rm = TRUE),
q1 = quantile(x, 0.25, na.rm = TRUE),
median = median(x, na.rm = TRUE),
mean = mean(x, na.rm = TRUE),
q3 = quantile(x, 0.75, na.rm = TRUE),
max = max(x, na.rm = TRUE),
iqr = IQR(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE)
)
)
}
# Apply the calculate_stats function to each numeric column in metadata
stats_summary <- t(sapply(numeric_metadata, calculate_stats))
# Convert stats summary to a data frame
stats_summary_df <- as.data.frame(stats_summary)
rm(stats_summary)
# Display the statistics summary as a formatted HTML table
kable(
stats_summary_df,
format = "html",
digits = 2,
row.names = TRUE
) %>%
kable_styling(
bootstrap_options = c("striped", "hover", "condensed"),
full_width = TRUE
) %>%
scroll_box(width = "100%", height = "400px")
table_dict$initial_stats_summary_df <- stats_summary_df
rm(stats_summary_df)
# Initialize a list to store plots
plot_list <- list()
# Loop through each numeric metadata column to create histograms, density plots, and box plots
for (col in colnames(numeric_metadata)) {
# Histogram
p_hist <- ggplot(gbm@meta.data, aes_string(x = col)) +
geom_histogram(bins = 30,
color = "black",
fill = "lightblue") +
labs(title = paste("Histogram of", col),
x = col,
y = "Frequency") +
theme_minimal(base_size = 10) +  # Smaller base font size
theme(
plot.title = element_text(hjust = 0.5, size = 12),
# Adjust title font size
axis.title = element_text(size = 10),
# Axis title size
axis.text = element_text(size = 8)
)  # Axis text size
# Density Plot
p_density <- ggplot(gbm@meta.data, aes_string(x = col)) +
geom_density(fill = "lightblue", alpha = 0.5) +
labs(title = paste("Density Plot of", col),
x = col,
y = "Density") +
theme_minimal(base_size = 10) +
theme(
plot.title = element_text(hjust = 0.5, size = 12),
axis.title = element_text(size = 10),
axis.text = element_text(size = 8)
)
# Box Plot
p_box <- ggplot(gbm@meta.data, aes_string(x = "1", y = col)) +
geom_boxplot(fill = "lightblue") +
labs(title = paste("Box Plot of", col),
x = "",
y = col) +
theme_minimal(base_size = 10) +
theme(
plot.title = element_text(hjust = 0.5, size = 12),
axis.title = element_text(size = 10),
axis.text = element_text(size = 8)
)
# Combine the three plots into one row
combined_plot <- p_hist + p_density + p_box + plot_layout(ncol = 3)  # Arrange in a single row
# Add the combined plot to the list
plot_list[[col]] <- combined_plot
rm(combined_plot)
}
rm(col)
# Combine all plots into one big picture
final_plot <- wrap_plots(plot_list, ncol = 1) +  # Combine into a single column layout
plot_annotation(title = "Combined Plots for All Metrics",
theme = theme(plot.title = element_text(size = 16)))  # Add a title to the combined plot
plot_dict$Metrics_plot <- final_plot
# Display the final combined plot
print(final_plot)
rm(final_plot,
p_box,
p_density,
p_hist,
plot_list,
numeric_metadata)
# Convert Seurat object to SingleCellExperiment object for further analysis
gbm.sce = as.SingleCellExperiment(gbm)
gbm.sce = scDblFinder(gbm.sce, samples = "orig.ident", clusters = F)  # Detect doublets
# Log-transform the counts data
logcounts(gbm.sce) <- log1p(counts(gbm.sce))  # log1p(x) is log(1 + x)
# Display the number of doublets i66622dentified
table_dict$scDblFinder.class <- table(gbm.sce$scDblFinder.class)
table_dict$scDblFinder.class
# Convert SingleCellExperiment object back to Seurat object
gbm.seurat <- as.Seurat(gbm.sce, counts = "counts", data = "logcounts")
# Apply Quality Control: Doublet removal
gbm <- subset(gbm.seurat, subset = scDblFinder.class == "singlet")
rm(gbm.seurat, gbm.sce)
# Identify numeric columns in the metadata
numeric_metadata <- gbm@meta.data[, sapply(gbm@meta.data, function(x)
is.numeric(x) || is.integer(x))]
stats_summary <- t(sapply(numeric_metadata, calculate_stats))
# Convert stats_summary to a data frame if it isn't already
stats_summary_df <- as.data.frame(stats_summary)
kable(
stats_summary_df,
format = "html",
digits = 2,
row.names = TRUE
) %>%
kable_styling(
bootstrap_options = c("striped", "hover", "condensed"),
full_width = TRUE
) %>%
scroll_box(width = "100%", height = "400px")
table_dict$After_scDblFinder_stats_summary_df <- stats_summary_df
rm(stats_summary, numeric_metadata)
# Define thresholds using the interquartile range (IQR)
thresh_iqr = 5
nCount_RNA_upper = stats_summary_df["nCount_RNA", "q3.75%"] + thresh_iqr *
stats_summary_df["nCount_RNA", "iqr"]
nCount_RNA_lower = stats_summary_df["nCount_RNA", "q1.25%"] - thresh_iqr *
stats_summary_df["nCount_RNA", "iqr"]
nFeature_RNA_upper = stats_summary_df["nFeature_RNA", "q3.75%"] + thresh_iqr *
stats_summary_df["nFeature_RNA", "iqr"]
nFeature_RNA_lower = stats_summary_df["nFeature_RNA", "q1.25%"] - thresh_iqr *
stats_summary_df["nFeature_RNA", "iqr"]
rm(stats_summary_df)
# Subset the Seurat object based on the calculated thresholds
gbm = subset(
gbm,
subset = nCount_RNA >= nCount_RNA_lower &
nCount_RNA <= nCount_RNA_upper
&
nFeature_RNA >= nFeature_RNA_lower &
nFeature_RNA <= nFeature_RNA_upper
)
rm(
nCount_RNA_upper,
nCount_RNA_lower,
nFeature_RNA_upper,
nFeature_RNA_lower,
thresh_iqr
)
# Function to identify outliers based on median absolute deviation (MAD)
is_outlier <- function(scdata, metric, nmads) {
M <- scdata@meta.data[, metric]
outlier <- (M < median(M) - nmads * mad(M)) |
(median(M) + nmads * mad(M) < M)
return(outlier)
}
# Identify and mark outliers
gbm@meta.data["outlier"] = (is_outlier(gbm, "nCount_RNA", 5) |
is_outlier(gbm, "nFeature_RNA", 5))
gbm@meta.data["ribo_outlier"] = is_outlier(gbm, "percent.ribo", 3)
gbm@meta.data["hb_outlier"] = is_outlier(gbm, "percent.hb", 3)
gbm@meta.data["ERCC_outlier"] = is_outlier(gbm, "percent.ERCC", 3)
gbm@meta.data["mt_outlier"] = is_outlier(gbm, "percent.mt", 3)
gbm@meta.data["all_outliers"] <- gbm@meta.data["outlier"] |
gbm@meta.data["ribo_outlier"] |
gbm@meta.data["hb_outlier"] |
gbm@meta.data["ERCC_outlier"] | gbm@meta.data["mt_outlier"]
# Display the number of outliers
table(gbm@meta.data["all_outliers"])
# Subset the Seurat object to exclude outliers
gbm <- subset(gbm, subset = outlier == FALSE)
# Normalize, find variable features, and scale data
gbm <- SCTransform(
gbm,
method = "glmGamPoi",
variable.features.n = 2000,
verbose = FALSE
)
# finding optimal pca factor
optimal_pcs = 50
opts = vector()
opts = append(opts, 50)
while (TRUE) {
gbm_test = RunPCA(gbm,
features = VariableFeatures(gbm),
npcs = optimal_pcs,
verbose = FALSE)
dim(gbm_test[["pca"]])[2]
stdev <- gbm_test[["pca"]]@stdev
cum_variance <- cumsum(stdev ^ 2) / sum(stdev ^ 2)
optimal_pcs <- which(cum_variance > 0.9)[1]
opts <- append(opts, optimal_pcs)
if (length(opts) > 3) {
if (opts[length(opts) - 1] - opts[length(opts) - 2] > opts[length(opts)] - opts[length(opts)] -
1) {
break
}
}
}
npcs_n = ceiling(sum(opts) / length(opts))
rm(e, cum_variance, optimal_pcs, opts, stdev, gbm_test)
# running with optimal pca
gbm = RunPCA(gbm, features = VariableFeatures(gbm), npcs = npcs_n)
e = ElbowPlot(gbm, ndims = npcs_n)
plot_dict$elbowPCA <- e
rm(e)
all_dims = list()
for (i in 1:npcs_n) {
for (j in i:npcs_n) {
if (j <= i) {
next
}
d = DimPlot(
gbm ,
reduction = "pca",
dims = c(i, j),
group.by = "patient.name",
pt.size = 0.5,
) + theme_cowplot(font_size = 4) + guides(color = guide_legend(override.aes = list(size =
0.5), ncol = 1))
all_dims[[paste(i, "-", j)]] <- d
}
}
plot_dict$all_dims <- all_dims
rm(i, j, d, npcs_n, all_dims)
wrap_plots(plot_dict$all_dims$`1 - 2`, plot_dict$all_dims$`2 - 3`)
wrap_plots(plot_dict$all_dims)
# Find neighbors and clusters
gbm <- FindNeighbors(gbm, dims = 1:dim(gbm[["pca"]])[2], reduction = "pca")
get_string_data_modularity <- function(gbm, res) {
output <- capture.output(FindClusters(
gbm,
resolution = res,
method = "igraph",
n.iter = 100
))
# Convert the output to a single string
output_text <- paste(output, collapse = " ")
modularity_value <- str_extract(output_text,
"Maximum modularity in 10 random starts: \\d+\\.\\d*")
modularity_numeric <- as.numeric(str_extract(modularity_value, "\\d+\\.\\d*"))
communities_value <- str_extract(output_text, "Number of communities: \\d+")
communities_numeric <- as.numeric(str_extract(communities_value, "\\d+"))
return(list(modularity = modularity_numeric, communities = communities_numeric))
}
count_floating_point_digits <- function(number) {
# Convert the number to a string and split by the decimal point
number_str <- as.character(number)
split_number <- strsplit(number_str, "\\.")[[1]]
# Calculate the number of digits after the decimal point
if (length(split_number) > 1) {
floating_point_digits <- nchar(split_number[[2]])
} else {
floating_point_digits <- 0  # If there's no decimal point
}
return(floating_point_digits)
}
target_communities = 2
depth = 0.0001
tlow = 0
thigh = 2
t_depth = 0.1
best_modularities = data.frame()
while (TRUE) {
print(t_depth)
all_t = seq(tlow, thigh, t_depth)
all_t_res = data.frame()
for (tt in all_t) {
x = get_string_data_modularity(gbm, tt)
temp_df <- data.frame(
tt = as.character(tt),
modularity = x$modularity,
communities = x$communities
)
# Combine the temporary data frame with the main results data frame
all_t_res <- rbind(all_t_res, temp_df)
}
all_t_res$tt <- as.numeric(as.character(all_t_res$tt))
community_2_res <- subset(all_t_res, communities == target_communities)
# Find the lowest and highest `tt` values
lowest_tt <- min(community_2_res$tt)
highest_tt <- max(community_2_res$tt)
max_index <- which.max(community_2_res$modularity)
max_row <- community_2_res[max_index, ]
best_modularities <- rbind(best_modularities,max_row)
tlow = lowest_tt - t_depth
thigh = lowest_tt + t_depth
type(t_depth)
if (isTRUE(all.equal(t_depth, depth))) {
max_index <- which.max(best_modularities$modularity)
max_row <- best_modularities[max_index, ]
best_modularities <- max_row
colnames(best_modularities)[colnames(best_modularities) == "tt"] <- "best_resolution"
break
}
t_depth = t_depth * 0.1
}
# Print the modularity value
table_dict$best_modularity_clustering = best_modularities
rm(community_2_res,all_t_res,temp_df,x,all_t,depth,highest_tt,lowest_tt,max_index,t_depth,tt,tlow,thigh,target_communities,best_modularities)
gbm <- FindClusters(gbm,
resolution = table_dict$best_modularity_clustering$best_resolution,
method = "igraph",
n.iter = 100)
gbm <- FindClusters(gbm,
resolution =1,
method = "igraph",
n.iter = 100)
# Run UMAP and t-SNE for visualization
gbm <- RunUMAP(gbm, reduction = "pca", dims = 1:dim(gbm[["pca"]])[2])
gbm <- RunTSNE(gbm,
reduction = "pca",
dims = 1:dim(gbm[["pca"]])[2],
perplexity = 30)
# Plot UMAP and t-SNE results
colnames(gbm@meta.data)
p1_umap <- DimPlot(object = gbm, reduction = "umap",group.by = "seurat_clusters")
p2_umap <- DimPlot(object = gbm,
reduction = "umap",
group.by = "patient.name")
# Plot t-SNE results
p1_tsne <- DimPlot(object = gbm, reduction = "tsne",group.by = "seurat_clusters")
p2_tsne <- DimPlot(object = gbm,
reduction = "tsne",
group.by = "patient.name")
# Combine t-SNE plots into a grid
plot_grid(p1_umap,p2_umap,p1_tsne, p2_tsne, labels = c("A","B","C", "D"))
ref <- HumanPrimaryCellAtlasData()
# Perform cell type annotation
singleR_results <- SingleR(test = gbm@assays$RNA@data, ref = ref, labels = ref$label.main)
# Add SingleR results to the Seurat metadata
gbm$SingleR_labels <- singleR_results$labels
gbm@meta.data$cell_type_markers <- gbm@meta.data$SingleR_labels
memory.limit(9999999999)
df <- data.frame(gbm@meta.data$cell_type_markers, gbm@meta.data$patient.name)
colnames(df) <- c("Cell_Type", "Patient")
df <- df %>% group_by(Patient, Cell_Type) %>%
summarise(Nb = n()) %>%
mutate(C = sum(Nb)) %>%
mutate(Percent = Nb/C*100)
ggplot(df, aes(fill=Cell_Type, y=Percent, x=Patient)) +
geom_bar(position="fill", stat="identity") + scale_fill_viridis(discrete = T) + xlab("") +
theme(legend.position='top', axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
Idents(gbm) = gbm@meta.data$cell_type_markers
gbm.markers = FindAllMarkers(gbm, min.pct = 0.1, logfc.threshold = 0.25,
test.use = "MAST")
gbm.markers %>% group_by(cluster) %>% top_n(n = 10, wt = avg_log2FC) -> top10
DoHeatmap(gbm, features = top10$gene) + NoLegend()
clusters <- unique(gbm.markers$cluster)
gsea_results_list <- list()
for (cluster in clusters) {
# Filter marker genes for the current cluster
Marker_cluster <- gbm.markers[gbm.markers$cluster == cluster, c(1, 2, 5, 7)]
# Prepare the gene list for GSEA
original_gene_list <- Marker_cluster$avg_log2FC
names(original_gene_list) <- Marker_cluster$gene
gene_list <- na.omit(original_gene_list)
gene_list <- sort(gene_list, decreasing = TRUE)
# Run GSEA for this cluster
gse <- gseGO(geneList = gene_list,
ont = "ALL",
keyType = "SYMBOL",
pvalueCutoff = 0.05,
OrgDb = org.Hs.eg.db,
pAdjustMethod = "BH")
gsea_results_list[[cluster]] <- gse
# Optional: Visualize the results for this cluster
print(paste("Cluster:", cluster))
dotplot(gse, showCategory = 5, split = ".sign") + facet_grid(. ~ .sign) + ggtitle(paste("GSEA for Cluster", cluster))
}
pheatmap(avg_expression_matrix[top_genes_pm, ],
cluster_rows = TRUE,
cluster_cols = FALSE,  # No clustering for columns to keep BC07 and BC07LN separate
display_numbers = FALSE)
Idents(gbm) <- 'seurat_clusters'
cluster.markers <- FindAllMarkers(
object = gbm,
only.pos = TRUE,
min.pct = 0.25,
logfc.threshold = 0.25,
test.use = "MAST"
)
top_genes <- rownames(cluster.markers)
DoHeatmap(gbm, features = top_genes)
DEG_bc07_bc07ln <- FindMarkers(gbm, ident.1 = "BC07", ident.2 = "BC07LN", group.by = "patient.name")
top_genes_pm <- rownames(DEG_bc07_bc07ln)[1:100]
avg_expression <- AverageExpression(gbm, features = top_genes_pm, group.by = "patient.name")
avg_expression_matrix <- avg_expression$SCT
pheatmap(avg_expression_matrix[top_genes_pm, ],
cluster_rows = TRUE,
cluster_cols = FALSE,  # No clustering for columns to keep BC07 and BC07LN separate
display_numbers = FALSE)
top10_genes <- rownames(DEG_bc07_bc07ln)[1:10]
# View the top 10 genes
print(top10_genes)
gene_list <- DEG_bc07_bc07ln$avg_log2FC
names(gene_list) <- rownames(DEG_bc07_bc07ln)
# Step 2: Perform Gene Ontology (GO) enrichment analysis
go_enrichment <- enrichGO(gene = top10_genes,
OrgDb = org.Hs.eg.db,
keyType = "SYMBOL",
ont = "ALL",  # You can choose "BP" (Biological Process), "MF" (Molecular Function), or "CC" (Cellular Component)
pvalueCutoff = 0.05,
qvalueCutoff = 0.05)
# Step 3: Perform KEGG pathway enrichment analysis (optional)
kegg_enrichment <- enrichKEGG(gene = top10_genes,
organism = 'hsa',  # 'hsa' is the KEGG code for Homo sapiens (human)
pvalueCutoff = 0.05)
# Step 4: Visualize the results of enrichment analysis
# Visualize GO enrichment results
dotplot(go_enrichment, showCategory = 10, title = "GO Enrichment Analysis for Top 10 Genes")
# Visualize KEGG enrichment results (if applicable)
dotplot(kegg_enrichment, showCategory = 10, title = "KEGG Pathway Analysis for Top 10 Genes")
# Step 4: Visualize the results of enrichment analysis
# Visualize GO enrichment results
dotplot(go_enrichment, showCategory = 10, title = "GO Enrichment Analysis for Top 10 Genes")
# Visualize KEGG enrichment results (if applicable)
dotplot(kegg_enrichment, showCategory = 10, title = "KEGG Pathway Analysis for Top 10 Genes")
kegg_enrichment
top10_genes
# Step 3: Perform KEGG pathway enrichment analysis (optional)
kegg_enrichment <- enrichKEGG(gene = top10_genes,
organism = 'hsa',  # 'hsa' is the KEGG code for Homo sapiens (human)
pvalueCutoff = 0.05)
top10_genes
top10_genes
top10_genes
top10_genes
top10_genes
enrich_genes <- function(gene_list,databases){
enr= enrichr(gene_list,databases)
for (i in seq_along(enr)){
cat("\nDatabase:",names(enr)[i],"\n")
print(head(enr[[i]]),10)
}
return(enr)
}
websiteLive <- getOption("enrichR.live")
if (websiteLive) {
listEnrichrSites()
setEnrichrSite("Enrichr") # Human genes
}
if (websiteLive) dbs <- listEnrichrDbs()
dbs$libraryName
top10_genes
library_names = c("KEGG_2021_Human",
"Reactome_2022",
"GO_Biological_Process_2023",
"GO_Molecular_Function_2023",
"GO_Cellular_Component_2023",
"OMIM_Disease",
"OMIM_Expanded",
"DisGeNET",
"Human_Phenotype_Ontology",
"WikiPathway_2023_Human",
"MSigDB_Hallmark_2020",
"BioCarta_2016")
enrich_genes(top10_genes,library_names)
result_enrich = enrich_genes(top10_genes,library_names)
View(result_enrich)
result_enrich[["KEGG_2021_Human"]]
result_enrich[["Reactome_2022"]]
result_enrich[["GO_Biological_Process_2023"]]
options("max.print") = 10000000000000000000
options(max.print = .Machine$integer.max)
result_enrich[["GO_Biological_Process_2023"]]
clear
result_enrich[["GO_Biological_Process_2023"]]
result_enrich[["GO_Molecular_Function_2023"]]
result_enrich[["GO_Cellular_Component_2023"]]
result_enrich[["GO_Biological_Process_2023"]]
result_enrich[["GO_Biological_Process_2023"]]
result_enrich[["GO_Molecular_Function_2023"]]
result_enrich[["GO_Cellular_Component_2023"]]
result_enrich[["OMIM_Disease"]]
result_enrich[["OMIM_Expanded"]]
result_enrich[["DisGeNET"]]
result_enrich[["DisGeNET"]]
result_enrich[["DisGeNET"]][, c("Term", "Genes")]
result_enrich[["DisGeNET"]][, c("Term", "Genes")]
# Copy the Term and Genes columns to the clipboard
writeClipboard(capture.output(result_enrich[["DisGeNET"]][, c("Term", "Genes")]))
# Now you can paste it elsewhere using Ctrl +
Genes
writeClipboard(capture.output(result_enrich[["DisGeNET"]][, c("Term", "Genes")]))
result_enrich[["Human_Phenotype_Ontology"]]
result_enrich[["WikiPathway_2023_Human"]]
result_enrich[["MSigDB_Hallmark_2020"]]
result_enrich[["BioCarta_2016"]]
